# 实现一个Go并发连接池

因为TCP三次握手等等原因，建立一个连接是一件成本比较高的行为。所以在一个需要多次与特定实体交互的程序中，就需要维持一个连接池，里面有可以复用的连接可供重复使用。

## 实现简单的连接池

### 结构定义

```go
type Pool struct {
    m       sync.Mutex                  //保证多个goroutine访问的时候，closed的线程安全
    res     chan io.Closer              //连接存储的chan
    factory func() (io.Closer,error)    //新建连接的工厂方法
    closed  bool                        //连接池关闭标志
}
```
这个简单的连接池使用chan来存储池里的连接，而新建结构体的方法也比较简单，只需要提供对应的工厂函数和连接池大小就可以了。

```go
func New(fn func() (io.Closer, error), size uint) (*Pool, error) {
    if size <= 0 {
        return nil, errors.New("size的值太小了")
    }
    return &Pool{
        factory: fn,
        res:     make(chan io.Closer, size),
    }, nil
}
```
### 获取连接

因为内部存储连接的结构是chan，所以只需要简单的select就可以保证线程安全

```go
func (p *Pool) Acquire() (io.Closer, error) {
    select {
    case r, ok := <-p.res:
        log.Println("Acquire：共享资源")
        if !ok {
            return nil, ErrPoolClosed
        }
        return r, nil
    default:
        log.Println("Acquire:新生成资源")   
        return p.factory()
    }
}
```
我们先从连接池的res这个chan里获取，如果没有的话我们就利用早已准备好的工厂函数进行构造连接。同时在从res获取连接的时候利用ok先确定这个连接池是否已经关闭，如果已经关闭我们就返回早已准备好的连接已关闭的错误。

### 关闭连接池

```go
//关闭连接池，释放资源
func(p *Pool) Close() {
    p.m.Lock()
    defer p.m.Unlock()

    if p.closed {
        return 
    }

    p.closed = true

    //关闭通道，不让写入
    close(p.res)

    //关闭通道里的资源
    for r := range p.res {
        r.Close()
    }
}
```
这边我们需要先进行p.m.Lock()上锁操作，这么做是因为需要对结构体里面的closed进行读写。需要先把这个标志位设定后，关闭res这个chan，使得Acquire方法再获取新的连接。我们再对res这个chan里面的连接进行Close操作。

### 释放连接

释放连接首先得有个前提，就是连接池还没有关闭。如果连接池已经关闭再往res里面送连接的话就好触发panic。

```go
func (p *Pool) Release(r io.Closer) {
    //保证该操作和Close方法的操作是安全的
    p.m.Lock()
    defer p.m.Unlock()

    //资源池都关闭了，就剩这一个没有释放的资源了，释放即可
    if p.closed {
        r.Close()
        return
    }

    select {
    case p.res <- r:
        log.Println("资源释放到池子里了")
    default:
        log.Println("资源池满了，释放这个资源吧")
        r.Close()    
    }

}
```
以上就是一个简单的线程安全的连接池实现方式了。我们可以看到的是，现在连接池虽然已经实现了，但是还有几个小缺点：

1. 我们对连接最大的数量没有限制，如果线程池空的话都我们默认就直接新建一个连接返回了。一旦并发量高的话将会不断新建连接，很容易（尤其是MySQL）造成too many connections的报错发生。

2. 既然我们需要保证最大可获取连接数量，那么我们就不希望数量定的太死。希望空闲的时候可以维护一定的空闲连接数量idleNum，但是又希望我们能限制最大可获取连接数量maxNum。

3. 第一种情况是并发过多的情况，那么如果并发量过少呢？现在我们在新建一个连接并且归还后，我们很长一段时间不再使用这个连接。那么这个连接很有可能在几个小时甚至更长时间之前就已经建立的了。长时间闲置的连接我们并没有办法保证它的可用性。便有可能我们下次获取的连接是已经失效的连接。

